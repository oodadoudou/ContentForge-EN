import os
import shutil
from PIL import Image, ImageFile
import natsort
import sys
import traceback
import json
import time

try:
    import numpy as np
except ImportError:
    print("Error: This script requires the numpy library. Please install it with 'pip install numpy'.")
    sys.exit(1)

# --- Global Settings ---
ImageFile.LOAD_TRUNCATED_IMAGES = True
Image.MAX_IMAGE_PIXELS = None

# --- Directory and Filename Settings ---
MERGED_LONG_IMAGE_SUBDIR_NAME = "merged_long_img"
SPLIT_IMAGES_SUBDIR_NAME = "split_by_solid_band"
SUCCESS_MOVE_SUBDIR_NAME = "IMG"  # Successfully processed folders will be moved to this directory
LONG_IMAGE_FILENAME_BASE = "stitched_long_strip"
IMAGE_EXTENSIONS_FOR_MERGE = ('.png', '.jpg', '.jpeg', '.webp', '.bmp', '.gif', '.tiff', '.tif')

# ▼▼▼ V4 Core Split Configuration (Two-stage color homogeneity analysis) ▼▼▼
QUANTIZATION_FACTOR = 32
MAX_UNIQUE_COLORS_IN_BG = 5
MIN_SOLID_COLOR_BAND_HEIGHT = 30
EDGE_MARGIN_PERCENT = 0.10

# --- Repack and PDF Output Settings ---
MAX_REPACKED_FILESIZE_MB = 8
MAX_REPACKED_PAGE_HEIGHT_PX = 30000
PDF_TARGET_PAGE_WIDTH_PIXELS = 1500
PDF_IMAGE_JPEG_QUALITY = 90
PDF_DPI = 300
# --- End of Settings ---


def print_progress_bar(iteration, total, prefix='', suffix='', decimals=1, length=50, fill='█', print_end="\r"):
    """Prints a progress bar in the terminal."""
    if total == 0:
        percent_str = "0.0%"
        filled_length = 0
    else:
        percent = ("{0:." + str(decimals) + "f}").format(100 * (iteration / float(total)))
        percent_str = f"{percent}%"
        filled_length = int(length * iteration // total)

    bar = fill * filled_length + '-' * (length - filled_length)
    sys.stdout.write(f'\r{prefix} |{bar}| {percent_str} {suffix}')
    sys.stdout.flush()
    if iteration == total:
        sys.stdout.write('\n')
        sys.stdout.flush()


def merge_to_long_image(source_project_dir, output_long_image_dir, long_image_filename_only, target_width):
    """Vertically merges all images (including subdirectories) into a PNG long image of standard width."""
    print(f"\n  --- Step 1: Merge images in project '{os.path.basename(source_project_dir)}' to standard width {target_width}px ---")
    if not os.path.isdir(source_project_dir):
        print(f"    Error: Source project directory '{source_project_dir}' not found.")
        return None

    os.makedirs(output_long_image_dir, exist_ok=True)
    output_long_image_path = os.path.join(output_long_image_dir, long_image_filename_only)
    
    print(f"    ... Recursively scanning '{os.path.basename(source_project_dir)}' and all subfolders for images ...")
    image_filepaths = []
    try:
        for dirpath, _, filenames in os.walk(source_project_dir):
            if MERGED_LONG_IMAGE_SUBDIR_NAME in dirpath or SPLIT_IMAGES_SUBDIR_NAME in dirpath:
                continue
            for filename in filenames:
                if filename.lower().endswith(IMAGE_EXTENSIONS_FOR_MERGE) and not filename.startswith('.'):
                    image_filepaths.append(os.path.join(dirpath, filename))
    except Exception as e:
        print(f"    Error: An error occurred while scanning directory '{source_project_dir}': {e}")
        return None

    if not image_filepaths:
        print(f"    No eligible images found in '{os.path.basename(source_project_dir)}' or its subdirectories.")
        return None

    sorted_image_filepaths = natsort.natsorted(image_filepaths)
    images_data, total_height = [], 0
    print_progress_bar(0, len(sorted_image_filepaths), prefix='    Analyzing and computing sizes:', suffix='Done', length=40)
    for i, filepath in enumerate(sorted_image_filepaths):
        try:
            with Image.open(filepath) as img:
                new_height = int(img.height * (target_width / img.width)) if img.width != target_width else img.height
                images_data.append({"path": filepath, "new_height": new_height})
                total_height += new_height
        except Exception as e:
            print(f"\n    Warning: Failed to open or read image '{os.path.basename(filepath)}': {e}. Skipped.")
            continue
        print_progress_bar(i + 1, len(sorted_image_filepaths), prefix='    Analyzing and computing sizes:', suffix='Done', length=40)

    if not images_data or target_width <= 0 or total_height <= 0:
        print(f"    Computed canvas size is invalid ({target_width}x{total_height}); cannot create long image.")
        return None

    merged_canvas = Image.new('RGB', (target_width, total_height), (255, 255, 255))
    current_y_offset = 0
    print_progress_bar(0, len(images_data), prefix='    Pasting images:    ', suffix='Done', length=40)
    for i, item_info in enumerate(images_data):
        try:
            with Image.open(item_info["path"]) as img:
                img_rgb = img.convert("RGB")
                img_to_paste = img_rgb.resize((target_width, item_info['new_height']), Image.Resampling.LANCZOS) if img_rgb.width != target_width else img_rgb
                merged_canvas.paste(img_to_paste, (0, current_y_offset))
                current_y_offset += item_info['new_height']
        except Exception as e:
            print(f"\n    Warning: Failed to paste image '{item_info['path']}': {e}.")
        print_progress_bar(i + 1, len(images_data), prefix='    Pasting images:    ', suffix='Done', length=40)

    try:
        merged_canvas.save(output_long_image_path, format='PNG')
        print(f"    Successfully merged images to: {output_long_image_path}")
        return output_long_image_path
    except Exception as e:
        print(f"    Error: Failed to save merged long image: {e}")
        return None

# ▼▼▼ V4 核心函数 - 两阶段色彩同质性分析 ▼▼▼
def get_dominant_color_numpy(pixels_quantized):
    """[V4 performance core] Use pure NumPy to find the dominant color from quantized pixel blocks."""
    if pixels_quantized.size == 0:
        return None, 0
    pixels_list = pixels_quantized.reshape(-1, 3)
    unique_colors, counts = np.unique(pixels_list, axis=0, return_counts=True)
    num_unique_colors = len(unique_colors)
    if num_unique_colors == 0:
        return None, 0
    dominant_color = tuple(unique_colors[np.argmax(counts)])
    return dominant_color, num_unique_colors

def split_long_image_v4(long_image_path, output_split_dir, quantization_factor, max_unique_colors, min_band_height, edge_margin_percent):
    """
    [V4 core logic] Identifies and splits the image via two-stage vectorized analysis for high speed.
    """
    print(f"\n  --- Step 2 (V4 - two-stage fast analysis): Split long image '{os.path.basename(long_image_path)}' ---")
    start_time = time.time()
    if not os.path.isfile(long_image_path):
        print(f"    Error: Long image path '{long_image_path}' not found.")
        return []

    os.makedirs(output_split_dir, exist_ok=True)
    
    try:
        with Image.open(long_image_path) as img:
            img_rgb = img.convert("RGB")
            img_width, img_height = img_rgb.size
            if img_height < min_band_height * 3: # If the image is too short, splitting is unnecessary
                print("    Image too short; no need to split.")
                dest_path = os.path.join(output_split_dir, os.path.basename(long_image_path))
                shutil.copy2(long_image_path, dest_path)
                return [dest_path]

            print(f"    Analyzing an image of {img_width}x{img_height}...")
            print("    [1/3] Color quantization...")
            quantized_array = np.array(img_rgb) // quantization_factor
            
            margin_width = int(img_width * edge_margin_percent)
            center_start, center_end = margin_width, img_width - margin_width

            # --- [V4 Core Optimization 1: Fast candidate screening] ---
            print("    [2/3] Fast screening of candidate rows...")
            candidate_indices = []
            candidate_dominant_colors = {}
            # Still per-row, but only analyze the fastest center region
            for y in range(img_height):
                center_pixels = quantized_array[y, center_start:center_end]
                dominant_color, color_count = get_dominant_color_numpy(center_pixels)
                if color_count <= max_unique_colors and dominant_color is not None:
                    candidate_indices.append(y)
                    candidate_dominant_colors[y] = dominant_color
            
            if not candidate_indices:
                print("    No candidate rows found; no split needed.")
                dest_path = os.path.join(output_split_dir, os.path.basename(long_image_path))
                shutil.copy2(long_image_path, dest_path)
                return [dest_path]

            # --- [V4 Core Optimization 2: Precise edge verification] ---
            print(f"    [3/3] Precisely verifying edges across {len(candidate_indices)} candidate rows...")
            row_types = np.full(img_height, 'complex', dtype=object)
            # Perform expensive edge analysis only for a small number of candidate rows
            for y in candidate_indices:
                center_dominant_color = candidate_dominant_colors[y]
                
                # 分析左边缘
                left_pixels = quantized_array[y, :margin_width]
                left_dominant_color, left_color_count = get_dominant_color_numpy(left_pixels)
                if left_color_count > max_unique_colors or left_dominant_color != center_dominant_color:
                    continue

                # 分析右边缘
                right_pixels = quantized_array[y, -margin_width:]
                right_dominant_color, right_color_count = get_dominant_color_numpy(right_pixels)
                if right_color_count > max_unique_colors or right_dominant_color != center_dominant_color:
                    continue
                
                row_types[y] = 'simple'
            
            analysis_duration = time.time() - start_time
            print(f"    Analysis completed in: {analysis_duration:.2f} seconds.")

            # --- Subsequent block detection and saving logic ---
            blocks, last_y = [], 0
            change_points = np.where(row_types[:-1] != row_types[1:])[0] + 1
            for y_change in change_points:
                blocks.append({'type': row_types[last_y], 'start': last_y, 'end': y_change})
                last_y = y_change
            blocks.append({'type': row_types[last_y], 'start': last_y, 'end': img_height})
            
            original_basename, _ = os.path.splitext(os.path.basename(long_image_path))
            part_index, last_cut_y, cut_found = 1, 0, False
            split_image_paths = []
            
            print(f"    Searching cut points among {len(blocks)} content/blank blocks...")
            for i, block in enumerate(blocks):
                if block['type'] == 'simple' and (block['end'] - block['start']) >= min_band_height:
                    if i > 0 and i < len(blocks) - 1:
                        cut_found = True
                        cut_point_y = block['start'] + (block['end'] - block['start']) // 2
                        segment = img_rgb.crop((0, last_cut_y, img_width, cut_point_y))
                        output_filename = f"{original_basename}_split_part_{part_index}.png"
                        output_filepath = os.path.join(output_split_dir, output_filename)
                        segment.save(output_filepath, "PNG")
                        split_image_paths.append(output_filepath)
                        print(f"      Found eligible blank area at Y={cut_point_y}; split and saved: {output_filename}")
                        part_index += 1
                        last_cut_y = cut_point_y

            segment = img_rgb.crop((0, last_cut_y, img_width, img_height))
            output_filename = f"{original_basename}_split_part_{part_index}.png"
            output_filepath = os.path.join(output_split_dir, output_filename)
            segment.save(output_filepath, "PNG")
            split_image_paths.append(output_filepath)
            
            if not cut_found:
                print("\n    [V4 Diagnostic Report] No eligible blank areas found for splitting.")
                print(f"    Consider checking parameters: MAX_UNIQUE_COLORS_IN_BG={max_unique_colors}, MIN_SOLID_COLOR_BAND_HEIGHT={min_band_height}")
                if len(split_image_paths) == 1:
                    os.remove(split_image_paths[0])
                dest_path = os.path.join(output_split_dir, os.path.basename(long_image_path))
                shutil.copy2(long_image_path, dest_path)
                print("    Since no splits were performed, the original image was copied to the output directory.")
                return [dest_path]

            return natsort.natsorted(split_image_paths)

    except Exception as e:
        print(f"    Critical error while splitting image '{os.path.basename(long_image_path)}': {e}")
        traceback.print_exc()
        return []


def _merge_image_list_for_repack(image_paths, output_path):
    """Internal merge function specifically for repacking."""
    if not image_paths: return False
    images_data, total_height, target_width = [], 0, 0
    for path in image_paths:
        try:
            with Image.open(path) as img:
                if target_width == 0: target_width = img.width
                images_data.append({"path": path, "height": img.height})
                total_height += img.height
        except Exception: continue
    if not images_data or target_width == 0: return False
    merged_canvas = Image.new('RGB', (target_width, total_height))
    current_y = 0
    for item in images_data:
        with Image.open(item["path"]) as img:
            merged_canvas.paste(img.convert("RGB"), (0, current_y))
            current_y += item["height"]
    merged_canvas.save(output_path, "PNG")
    return True


def repack_split_images(split_image_paths, output_dir, base_filename, max_size_mb, max_height_px):
    """Repack split images under 'dual constraints'."""
    print(f"\n  --- Step 2.5: Repack under dual constraints (limits: {max_size_mb}MB, {max_height_px}px) ---")
    if not split_image_paths or len(split_image_paths) <= 1:
        print("    Only one or no image block present; repacking not needed.")
        return split_image_paths

    max_size_bytes = max_size_mb * 1024 * 1024
    os.makedirs(output_dir, exist_ok=True)
    repacked_paths, current_bucket_paths, current_bucket_size, current_bucket_height = [], [], 0, 0
    repack_index = 1

    for img_path in split_image_paths:
        try:
            file_size = os.path.getsize(img_path)
            with Image.open(img_path) as img: img_height = img.height
        except Exception as e:
            print(f"\n    Warning: Unable to read attributes of image '{os.path.basename(img_path)}': {e}")
            continue
        
        if current_bucket_paths and ((current_bucket_size + file_size > max_size_bytes) or (current_bucket_height + img_height > max_height_px)):
            output_filename = f"{base_filename}_repacked_{repack_index}.png"
            output_path = os.path.join(output_dir, output_filename)
            if _merge_image_list_for_repack(current_bucket_paths, output_path):
                repacked_paths.append(output_path)
            repack_index += 1
            current_bucket_paths, current_bucket_size, current_bucket_height = [img_path], file_size, img_height
        else:
            current_bucket_paths.append(img_path)
            current_bucket_size += file_size
            current_bucket_height += img_height

    if current_bucket_paths:
        output_filename = f"{base_filename}_repacked_{repack_index}.png"
        output_path = os.path.join(output_dir, output_filename)
        if _merge_image_list_for_repack(current_bucket_paths, output_path):
            repacked_paths.append(output_path)
    
    print(f"    Repack complete; generated {len(repacked_paths)} new image block(s).")
    print("    ... Cleaning up original split files ...")
    original_files_to_clean = [p for p in split_image_paths if p not in repacked_paths]
    for path in original_files_to_clean:
        if os.path.exists(path): os.remove(path)
            
    return natsort.natsorted(repacked_paths)


def create_pdf_from_images(image_paths_list, output_pdf_dir, pdf_filename_only):
    """Create a PDF from a list of images."""
    print(f"\n  --- Step 3: Create PDF '{pdf_filename_only}' from image fragments ---")
    if not image_paths_list:
        print("    No images available to create a PDF.")
        return None

    safe_image_paths = []
    for image_path in image_paths_list:
        try:
            with Image.open(image_path) as img:
                if img.height > 65500 or img.width > 65500:
                    print(f"\n    Warning: Image '{os.path.basename(image_path)}' is too large; skipped.")
                else:
                    safe_image_paths.append(image_path)
        except Exception as e:
            print(f"    Warning: Unable to open image '{image_path}' for size check: {e}")
    
    if not safe_image_paths: return None

    os.makedirs(output_pdf_dir, exist_ok=True)
    pdf_full_path = os.path.join(output_pdf_dir, pdf_filename_only)
    
    images_for_pdf = [Image.open(p).convert('RGB') for p in safe_image_paths]
    if not images_for_pdf: return None

    try:
        images_for_pdf[0].save(pdf_full_path, save_all=True, append_images=images_for_pdf[1:], resolution=float(PDF_DPI), quality=PDF_IMAGE_JPEG_QUALITY, optimize=True)
        print(f"    Successfully created PDF: {pdf_full_path}")
        return pdf_full_path
    finally:
        for img_obj in images_for_pdf: img_obj.close()


def cleanup_intermediate_dirs(long_img_dir, split_img_dir):
    """Clean up intermediate file directories."""
    print(f"\n  --- Step 4: Clean up intermediate files ---")
    for dir_path in [long_img_dir, split_img_dir]:
        if os.path.isdir(dir_path):
            try:
                shutil.rmtree(dir_path)
                print(f"    Deleted intermediate folder: {dir_path}")
            except Exception as e:
                print(f"    Failed to delete folder '{dir_path}': {e}")


if __name__ == "__main__":
    print("Automated Image Batch Processing Workflow (V4 - Two-stage fast edition)")
    print("Workflow: 1.Merge -> 2.Split -> 2.5.Repack -> 3.Create PDF -> 4.Cleanup -> 5.Move successful items")
    print("-" * 70)
    
    def load_default_path_from_settings():
        """Read default work directory from shared settings file."""
        try:
            script_dir = os.path.dirname(os.path.abspath(__file__))
            settings_path = os.path.join(script_dir, 'shared_assets', 'settings.json')
            if not os.path.exists(settings_path):
                settings_path = os.path.join(os.path.dirname(script_dir), 'shared_assets', 'settings.json')
            with open(settings_path, 'r', encoding='utf-8') as f: return json.load(f).get("default_work_dir")
        except:
            return os.path.join(os.path.expanduser("~"), "Downloads")
    
    default_root_dir_name = load_default_path_from_settings() or "."

    root_input_dir = ""
    while True:
        prompt_message = (
            f"Please enter the [root directory] path containing one or more project subfolders.\n"
            f"The script will recursively process all images in each project subfolder.\n"
            f"(Press Enter to use the default path: '{default_root_dir_name}'): "
        )
        user_provided_path = input(prompt_message).strip()
        current_path_to_check = user_provided_path if user_provided_path else default_root_dir_name
        if not user_provided_path:
            print(f"Using default path: {current_path_to_check}")

        abs_path_to_check = os.path.abspath(current_path_to_check)
        if os.path.isdir(abs_path_to_check):
            root_input_dir = abs_path_to_check
            print(f"Selected root processing directory: {root_input_dir}")
            break
        else:
            print(f"Error: Path '{abs_path_to_check}' is not a valid directory or does not exist.")

    # 根据根目录名称创建唯一的PDF输出文件夹
    root_dir_basename = os.path.basename(os.path.abspath(root_input_dir))
    overall_pdf_output_dir = os.path.join(root_input_dir, f"{root_dir_basename}_pdfs")
    os.makedirs(overall_pdf_output_dir, exist_ok=True)
    
    # 创建用于存放成功处理项目的文件夹
    success_move_target_dir = os.path.join(root_input_dir, SUCCESS_MOVE_SUBDIR_NAME)
    os.makedirs(success_move_target_dir, exist_ok=True)

    # 扫描要处理的项目子文件夹，排除脚本的管理文件夹
    subdirectories = [d for d in os.listdir(root_input_dir)
                      if os.path.isdir(os.path.join(root_input_dir, d)) and \
                         d != SUCCESS_MOVE_SUBDIR_NAME and \
                         d != os.path.basename(overall_pdf_output_dir) and \
                         not d.startswith('.')]

    if not subdirectories:
        print(f"\n在根目录 '{root_input_dir}' 中未找到可处理的项目子文件夹。")
        sys.exit()

    sorted_subdirectories = natsort.natsorted(subdirectories)
    print(f"\n将按顺序处理以下 {len(sorted_subdirectories)} 个项目文件夹: {', '.join(sorted_subdirectories)}")
    failed_subdirs_list = []

    for i, subdir_name in enumerate(sorted_subdirectories):
        print(f"\n\n{'='*10} 开始处理项目: {subdir_name} ({i+1}/{len(sorted_subdirectories)}) {'='*10}")
        current_processing_subdir = os.path.join(root_input_dir, subdir_name)
        path_long_image_output_dir = os.path.join(current_processing_subdir, MERGED_LONG_IMAGE_SUBDIR_NAME)
        path_split_images_output_dir = os.path.join(current_processing_subdir, SPLIT_IMAGES_SUBDIR_NAME)
        
        # 每次都清理旧的中间文件，以防上次失败残留
        if os.path.isdir(path_long_image_output_dir): shutil.rmtree(path_long_image_output_dir)
        if os.path.isdir(path_split_images_output_dir): shutil.rmtree(path_split_images_output_dir)

        created_long_image_path = merge_to_long_image(
            current_processing_subdir, path_long_image_output_dir,
            f"{subdir_name}_{LONG_IMAGE_FILENAME_BASE}.png", PDF_TARGET_PAGE_WIDTH_PIXELS
        )

        pdf_created_for_this_subdir = False
        if created_long_image_path:
            # ▼▼▼ 调用 V4 两阶段分割函数 ▼▼▼
            split_segment_paths = split_long_image_v4(
                created_long_image_path, path_split_images_output_dir,
                QUANTIZATION_FACTOR, MAX_UNIQUE_COLORS_IN_BG,
                MIN_SOLID_COLOR_BAND_HEIGHT, EDGE_MARGIN_PERCENT
            )

            if split_segment_paths:
                repacked_final_paths = repack_split_images(
                    split_segment_paths, path_split_images_output_dir, base_filename=subdir_name,
                    max_size_mb=MAX_REPACKED_FILESIZE_MB, max_height_px=MAX_REPACKED_PAGE_HEIGHT_PX
                )

                if repacked_final_paths:
                    created_pdf_path = create_pdf_from_images(
                        repacked_final_paths, overall_pdf_output_dir, f"{subdir_name}.pdf"
                    )
                    if created_pdf_path: pdf_created_for_this_subdir = True

        if pdf_created_for_this_subdir:
            cleanup_intermediate_dirs(path_long_image_output_dir, path_split_images_output_dir)
            
            # --- 新增功能：移动处理成功的文件夹 ---
            print(f"\n  --- 步骤 5: 移动已成功处理的项目文件夹 ---")
            source_folder_to_move = current_processing_subdir
            destination_parent_folder = success_move_target_dir
            
            try:
                print(f"    准备将 '{os.path.basename(source_folder_to_move)}' 移动到 '{os.path.basename(destination_parent_folder)}' 文件夹中...")
                shutil.move(source_folder_to_move, destination_parent_folder)
                moved_path = os.path.join(destination_parent_folder, os.path.basename(source_folder_to_move))
                print(f"    成功移动文件夹至: {moved_path}")
            except Exception as e:
                print(f"    错误: 移动文件夹 '{os.path.basename(source_folder_to_move)}' 失败: {e}")
                if subdir_name not in failed_subdirs_list:
                    failed_subdirs_list.append(f"{subdir_name} (移动失败)")

        else:
            print(f"  ❌ 项目文件夹 '{subdir_name}' 未能成功生成PDF，将保留中间文件以供检查。")
            failed_subdirs_list.append(subdir_name)

        print(f"{'='*10} '{subdir_name}' 处理完毕 {'='*10}")
        print_progress_bar(i + 1, len(sorted_subdirectories), prefix="总进度:", suffix='完成', length=40)

    print("\n" + "=" * 70 + "\n【任务总结报告】\n" + "-" * 70)
    success_count = len(sorted_subdirectories) - len(failed_subdirs_list)
    print(f"总计处理项目: {len(sorted_subdirectories)} 个\n  - ✅ 成功: {success_count} 个\n  - ❌ 失败: {len(failed_subdirs_list)} 个")
    if failed_subdirs_list:
        print("\n失败项目列表 (已保留在原位):\n" + "\n".join(f"  - {d}" for d in failed_subdirs_list))
    print("-" * 70)
    print(f"所有成功生成的PDF文件（如有）已保存在: {overall_pdf_output_dir}")
    print(f"所有成功处理的原始项目文件夹（如有）已移至: {success_move_target_dir}")
    print("脚本执行完毕。")
